{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Yk2djzoPdkchhdf_GuLAbaFDHUA0Y14X",
      "authorship_tag": "ABX9TyMFqchYLQ0gWmmQH/PNC1rE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachindamle/Resources/blob/main/LangChainTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQCXXJpHcVj7",
        "outputId": "8602897c-9e0b-474c-dd5d-ea5ac3fbe16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/226.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.1 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sC5XQHVqgkpZ",
        "outputId": "a3ba9cce-82cf-4ec4-d354-07c2acd0f5f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "9Zhbs9zAc0zS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install\n",
        "!pip install -qU langchain\n",
        "!pip install -qU langchain-community\n",
        "!pip install -qU pypdf\n",
        "!pip install -qU chromadb\n",
        "!pip install -qU tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHyDeMz4c8qP",
        "outputId": "2dcec356-f593-4a52-b573-888204717565"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m1.8/2.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxamWT6EeAeQ",
        "outputId": "74677e61-a165-4bfc-8320-28b46c5e8d96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_pdf = !ls /content/drive/MyDrive/Learnings/ML4T\\ Notes.pdf\n",
        "path_to_pdf=path_to_pdf[0]\n",
        "print(path_to_pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcKTKktre7Or",
        "outputId": "97f31e31-8741-403d-81fd-a1288fde333f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Learnings/ML4T Notes.pdf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import AzureOpenAI\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "3lR18oy8jiNu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Learnings/ML4T Notes.pdf\")\n",
        "\n",
        "#Load the document by calling loader.load()\n",
        "pages = loader.load()\n",
        "\n",
        "print(len(pages))\n",
        "print(pages[0].page_content[0:500])\n",
        "\n",
        "print(pages[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0uTD6glgUXu",
        "outputId": "6ceb7d07-8b4b-4aab-89b9-5cf7443fd473"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148\n",
            "1\n",
            " \n",
            "These notes were compiled by Octavian Blaga in spring 2017 (thanks Octavian!)\n",
            " \n",
            "Introduction\n",
            " \n",
            "Should I buy stock?\n",
            " \n",
            "●\n",
            "What other stock do you have in your portfolio?\n",
            " \n",
            "●\n",
            "What do you think will predict stock prices?\n",
            " \n",
            "How does information affect the movement of the stock price?\n",
            " \n",
            "●\n",
            "How to build software to analyze and visualize these relationships\n",
            " \n",
            "●\n",
            "Details about how the stock exchanges work\n",
            " \n",
            "Machine Learning algos that can be used to build real trading strategies.\n",
            " \n",
            " \n",
            "Mini-courses:\n",
            " \n",
            "1.\n",
            "\n",
            "{'source': '/content/drive/MyDrive/Learnings/ML4T Notes.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rsplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
        "splits = rsplitter.split_documents(pages)\n",
        "print(len(splits))\n",
        "print(len(pages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPa3R1ASgdA5",
        "outputId": "44ddc128-bad4-4f24-a4d5-fc044635f6b3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272\n",
            "148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "vH011h5WlssN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the vector store\n",
        "persist_directory = 'docs/chroma/'\n",
        "vectorDB = Chroma.from_documents(documents=splits,\n",
        "                                     embedding=embeddings,\n",
        "                                     persist_directory=persist_directory)\n",
        "print(vectorDB._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3R58MgMmlSn",
        "outputId": "1580cbbb-d5e1-4f4b-d279-87e1723aed86"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"text-davinci-003\"\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name=model_name, temperature=0)"
      ],
      "metadata": {
        "id": "_e4Gl_pNtfe3"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
        "qaChain = RetrievalQA.from_chain_type(\n",
        "        llm,\n",
        "        retriever=vectorDB.as_retriever(),\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "    )"
      ],
      "metadata": {
        "id": "Oj2AKDR4vVz5"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AskMe(question):\n",
        "  result = qaChain({\"query\": question})\n",
        "  return result[\"result\"]"
      ],
      "metadata": {
        "id": "G2x-nGeIxNRr"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass question to the qa_chain\n",
        "question = \"What are major topics for this class?\"\n",
        "print(AskMe(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAcuWRHxvzQr",
        "outputId": "30930823-2eb9-4ea1-9822-913c65111d6d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The major topics for this class include understanding whether to buy stock, how information affects stock prices, building software to analyze and visualize stock relationships, details about how stock exchanges work, and machine learning algorithms for trading strategies. The class also includes mini-courses on manipulating financial data in Python, computational investing, and learning algorithms for trading. Thanks for asking!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass question to the qa_chain\n",
        "question = \"Summarize the document in 5000 words\"\n",
        "print(AskMe(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHhbBvQ_wz1S",
        "outputId": "93fa10a5-acce-4231-9a1d-edf4aaf492ef"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document discusses various methods people use to express their views on the stock market, specifically through exchange-traded options. It mentions different strategies like the butterfly, the broken wing butterfly, and the iron condors. It also refers to the Fundamental Law IR = IC*SQRT(BR). Thanks for asking!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass question to the qa_chain\n",
        "question = \"How machine learning can help trading?\"\n",
        "print(AskMe(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSYF69U3x5AQ",
        "outputId": "fbe78bbb-06a4-4d19-ac10-9b4fed10eeed"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine learning can help trading by creating predictive models that can forecast future prices for stocks or other assets. These models utilize historical data and proprietary information feeds to make accurate predictions. Thanks for asking!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass question to the qa_chain\n",
        "question = \"Who is Sachin Tendulkar?\"\n",
        "print(AskMe(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaLS-vzEyCTm",
        "outputId": "2ff7dcf6-87b9-4634-a17d-24cfe2a55ede"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know. Thanks for asking!\n"
          ]
        }
      ]
    }
  ]
}